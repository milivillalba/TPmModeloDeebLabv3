<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Encabezado con Botones</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="styloInfo.css">
  
</head>
<body>
  <nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="index.html">Volver al Modelo</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item active">
          <a class="nav-link" href="#sobre-modelo">Sobre Modelo</a>
        </li>
        <!-- Añade aquí el otro botón con tu enlace -->
      </ul>
    </div>
  </nav>
  <div class="container mt-5">
    <div id="sobre-modelo">
      <h2>Sobre el Modelo DeepLab v3</h2>
      <p>
        DeepLab v3 es un modelo avanzado de segmentación semántica desarrollado por Google. Utiliza una arquitectura basada en redes neuronales convolucionales profundas (CNN) para realizar segmentaciones precisas de imágenes.
      </p>
      <p>
        El objetivo principal de utilizar el modelo DeepLab v3 para segmentación semántica en el navegador es hacer accesible una tecnología avanzada de análisis de imágenes, mejorar la interactividad y usabilidad de aplicaciones web, automatizar tareas de visión por computadora, fomentar la innovación y permitir una fácil integración con sistemas existentes. Todo esto contribuye a crear experiencias de usuario más ricas y eficientes, tanto para consumidores como para desarrolladores.
      </p>
      <h2>¿Qué es la Segmentación Semántica?</h2>
      <p>
        La segmentación semántica es una técnica en visión por computadora cuyo objetivo es clasificar cada píxel de una imagen en una categoría específica. Por ejemplo, en una imagen de una carretera, se pueden identificar y diferenciar los píxeles que corresponden a coches, señales de tráfico, carreteras, etc.
      </p>
      <h2>¿Qué es DeepLab v3?</h2>
      <p>
        DeepLab v3 es un modelo avanzado de segmentación semántica desarrollado por Google. Utiliza una arquitectura basada en redes neuronales convolucionales profundas (CNN) para realizar segmentaciones precisas de imágenes.
      </p>
      <h2>Modelos Relacionados con DeepLab v3</h2>
      <p>Aparte de DeepLab v3, existen otros modelos relacionados que se utilizan en diferentes contextos:</p>
      <ol>
        <li><strong>DeepLab Pascal:</strong> Este modelo se especializa en la detección y segmentación de objetos en imágenes generales. Es útil para aplicaciones que requieren reconocimiento de objetos en diversas condiciones.</li>
        <li><strong>DeepLab Cityscapes:</strong> Diseñado para la segmentación de imágenes urbanas, este modelo puede identificar elementos como vehículos, peatones y edificios en entornos urbanos. Es ideal para aplicaciones de análisis urbano y de tráfico.</li>
        <li><strong>DeepLab ADE20K:</strong> Este modelo es capaz de segmentar imágenes con un alto nivel de detalle, identificando una amplia variedad de objetos y escenarios. Es adecuado para aplicaciones que requieren una comprensión detallada del entorno visual, como la realidad aumentada y la navegación autónoma.</li>
      </ol>
      <h2>Ejemplo de Funcionamiento</h2>
      <p>
        Para implementar DeepLab v3 en el navegador, generalmente se sigue el siguiente flujo:
      </p>
      <ol>
        <li><strong>Carga del Modelo:</strong> Se carga el modelo DeepLab v3 preentrenado en el navegador usando una librería como TensorFlow.js.</li>
        <li><strong>Preprocesamiento de la Imagen:</strong> La imagen de entrada se preprocesa para que sea compatible con el modelo (e.g., redimensionamiento y normalización).</li>
        <li><strong>Predicción:</strong> La imagen procesada se pasa a través del modelo para obtener las predicciones de la segmentación.</li>
        <li><strong>Postprocesamiento:</strong> Las predicciones se postprocesan para obtener el mapa de segmentación final, que se superpone a la imagen original o se muestra de alguna otra forma útil para el usuario.</li>
      </ol>
    </div>
  </div>
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.4/dist/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</body>
</html>
